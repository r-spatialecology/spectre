## THIS IS THE SCRIPT THAT BRINGS EVERYTHING TOGETHER TO RUN THE
## FUNCTIONS BUILT ELSE WHERE AND ACTUALLY GET THE OUTPUTS

###################################################################################
##+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+##
###################################################################################
## Setup

library(tidyverse)
library(raster)
library(iNEXT)
library(gdm)
library(reshape2)
library(rgdal)
library(bigmemory)
library(foreach)
library(doParallel)
devtools::load_all(".")

###################################################################################
##+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+##
###################################################################################
## Import all the required files from disk

## Import the landscape rasters generated by Netlogo
maps <- load_raster("data/", "*.asc")

### TODO REMOVE THIS STEP FOR FINAL IMPLEMENTATION
## To start with lets reduce these maps down to get everything running
maps <- crop(maps, extent(maps, 41, 50, 41, 50))

## Import the environmental data frame and filter out the jungle values
env <- read.table("data/EnvironmentalData_Mark2_reduced.txt", header=TRUE)

env$PlotID <- substr(env$PlotID, 2, 2)
env <- env %>% filter(PlotID != "J")

## Import the GDM built for the birds data
birds_gdm <- readRDS("data/Birds_gdm.rds")

###################################################################################
##+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+##
###################################################################################
## Calculate the input values required by the DynamicFOAM algorithm

## 1) Generate a table of simulated environmental data
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##
## Prepare lutmap (replace numbers with strings and convert to data frame)
lutmap <- maps[[4]]
lutmap[lutmap==4] <- "F"
lutmap[lutmap==2] <- "R"
lutmap[lutmap==1] <- "O"
lutdf <- as.data.frame(lutmap, xy=TRUE)
names(lutdf) <- c("x", "y", "lut")

## Generate environmental table:
envdat <- simulate_environmental_data(lutdf, env)

## 2) Alpha diversity / species richness
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##
bird_alpha <- round(exp(2.078083 + 0.027132 * maps[[2]] + 
                          0.010402 * maps[[1]] - 
                          0.476163 * maps[[5]] + 
                          2.201850 * maps[[3]]))

alpha_list <- as.vector(as.matrix(bird_alpha))

## 3) Beta diversity / dissimilarity
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##
## This is a bit of a bottleneck, so we run it in parallel, using big memory to 
## ensure it doesn't crash
# 
# ## Detect cores:
# no_cores <- 2
# 
# ## Generate a list with combinations of rows and cols we want to fill (only upper matrix and diagonal)
# m <- matrix(ncol = nrow(envdat), nrow=nrow(envdat))
# comb <- expand.grid(row = 1:nrow(m), col = 1:ncol(m)) # grid
# comb <- comb[lower.tri(m, diag = FALSE), ]
# rm(m)
# 
# rows_per_chunk <- nrow(comb) / no_cores
# comb$chunk <- rep(1:no_cores, each=rows_per_chunk)
# 
# ## Create big data matrix:
# predictions <- big.matrix(nrow=nrow(envdat), 
#                           ncol=nrow(envdat), 
#                           type="double", 
#                           init=NA, 
#                           backingfile = "bigmatrix.mat", 
#                           descriptorfile = "bigmatrix.desc")
# 
# ## Create parallel cluster:
# cl <- makeCluster(no_cores, outfile="cluster.log")
# registerDoParallel(cl)
# 
# ## Execute:
# t.start <- Sys.time()
# foreach(i = 1:no_cores, .packages = c("bigmemory", "dplyr", "gdm", "OurFOAM", "devtools")) %dopar%
#   {"finished with D of 5211"
#     devtools::load_all("F:/PostDoc/Gottingen/EFForTS/Focus3/Package/dynamicfoam")
#     t <- attach.big.matrix("bigmatrix.desc")
#     #mat_description <- bigmemory::describe(predictions)
#     #t <- attach.big.matrix(mat_description)
#     comb_chunk <- subset(comb, comb$chunk == i)
#     
#     for (j in 1:nrow(comb_chunk))
#     {
#       ind_row <- comb_chunk[j,]$row
#       ind_col <- comb_chunk[j,]$col
#       
#       t[ind_row, ind_col] <- OurFOAM::predict_pair_dissimilarity(ind_row, ind_col, envdat, birds_gdm)
#       
#       # progress <- data.frame(node=i, proc=(j / nrow(comb_chunk) * 100))
#       # if (progress$proc %% 0.1 == 0)
#       # {
#       #   write.table(progress, file="Outputs/progress.log", sep="\t", row.names=F, col.names=F, append=TRUE)
#       # }
#     }
#     NULL
#   }
# stopCluster(cl)
# t.end <- Sys.time()
# t.end - t.start

## 4) Gamma diversity / total number of species
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##
bird_species <- read_csv2("data/B09_Birds_plot.csv")
total_recorded_species <- rowSums(bird_species[-1])
estimated_species <- iNEXT::iNEXT(total_recorded_species, q=0, datatype="abundance")
estimated_gamma <- round(estimated_species$AsyEst[1,2]) #139

###################################################################################
##+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+##
###################################################################################
## Calculate the target (pairwise matrix of species in common derived from beta)
## Formula is: Cij = (1 - Bij)(ai + bj)/2

bmo <- attach.big.matrix("bigmatrix.desc")

target_matrix <- calculate_commonness(alpha_list, bmo)

###################################################################################
##+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+##
###################################################################################
## Run the optimization algorithm

species_grid <- run_optimization(alpha_list, estimated_gamma, target_matrix, 1500, 1000, 500)


species_grid <- run_optimization2(alpha_list, estimated_gamma, target_matrix, 1500, 1000, 500)

library(microbenchmark)
microbenchmark(r = run_optimization(alpha_list, estimated_gamma, target_matrix, 1500, 1000, 500),
               rcpp = run_optimization2(alpha_list, estimated_gamma, target_matrix, 1500, 1000, 500),
               times = 100)

library(microbenchmark)
microbenchmark(r = run_optimization(alpha_list, estimated_gamma, target_matrix, 15000, 1000, 500),
               rcpp = run_optimization2(alpha_list, estimated_gamma, target_matrix, 15000, 1000, 500),
               times = 10)
